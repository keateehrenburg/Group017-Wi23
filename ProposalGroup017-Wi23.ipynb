{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "Our goal is to train a binary classifier for predicting the outcomes of FIDE titled chess matches using higher order features that describe the contextual setting of the match with a focus on the accuracy or F1 metric of our classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Keate Ehrenburg\n",
    "- Omri Habot\n",
    "- Jacob Lamadrid\n",
    "- Alex Bumbalov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "The goal of this project is to examine the effectiveness of different models in predicting the outcome of a chess match. The data used in this project will contain features describing players’ technical skill and experience including the Elo rating of each player, the number of games they have played, the number of wins/losses/draws they have achieved, their age, and the length of the game. These are measured by observing the outcomes of every game in a player’s career. We will use this data to perform feature selection and single out the most relevant features, and then we will train the models and compare their predictive accuracies. Accuracy will be measured by classification error metrics including precision, recall, f1-score, and possibly others, which we will compare across models to observe their relative efficacies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Within the world of chess competitions and general play, machine learning and deep learning have been famously applied in such algorithms as Deep Blue, Stockfish, etc. These algorithms historically have aimed to predict the next best move to be executed as well as the win probability at any given position state <a name=\"maharaj\"></a>[<sup>[1]</sup>](#maharaj). This win probability is what we aim to place our project emphasis upon as in similar works in varying competitive settings, most relevant of which is found in esports win/loss classification based upon player/team rankings and typical movesets among many other features <a name=\"do\"></a>[<sup>[2]</sup>](#do). The application of these algorithms in returning win probability and outcome prediction has large impacts in the way one chooses to learn chess or the way in which a machine is taught how to play chess. This may also have implications for the way in which new strategies or entire play styles are formed. These implications have already manifested themselves in the competitive playspace as many players look towards Stockfish evaluations for input on their play or for other engines in which competition may aid in their training as “with the help of chess engines, Grandmasters are now able to plan prepare for their games in extreme depth, sometimes memorizing up to 15-20 moves of their openings” <a name=\"article\"></a>[<sup>[3]</sup>](#article)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The problem we will be aiming to address is determining which machine learning method best predicts the winner of a chess game depending on variables like participating players, player statistics and scores such as their Elo’s, the opening, and psychological factors of the players, among others. \n",
    "\n",
    "We plan to explore this problem by trying three different machine learning algorithms: logistic regression, random forest, and deep neural network. Logistic regression is a solid classification method. While we fear that it may be too simple for this task, we believe it is a simple baseline to compare with other, more complex models. We plan to try random forests because the complex decision boundaries may be sufficient for consistently accurate and generalizable predictions. Finally, we plan on using a deep neural network because it seems to be the baseline method used for very similar problems, and given our large dataset, we hope it will pick up on important nuances that are neglected by logistic regression and random forest. We will use labeled chess game data that denotes the winner of each game as well as the aforementioned variables that describe the game. Each model will be trained using the same (or similar) dataset and evaluated with the same set of classification error metrics such that we can compare their efficacies. These metrics include precision, recall, f1-score, and others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "DB Link: https://www.ficsgames.org/\n",
    "\n",
    "We'll using the Free Internet Chess Server (FICS) as our database for analysis. The size of the dataset that we use is to be determined, but will most likely have to be limited to the recent n-thousand matches.\n",
    "\n",
    "The database consists of the moves made, date and time played, player Elo, match result, and game variant and time control information for each match.\n",
    "\n",
    "During preprocessing, plan to construct several features from the above set; namely game/player-specific features as well as those relating to recent form. These features are directly computable from match data for each player in the database, though some features may prove obsolete or too computationally demanding. \n",
    "\n",
    "The dataset will contain many FIDE titled matches, with each game represented by various features that describe the players, the game itself, and its outcome.\n",
    "\n",
    "\n",
    "Each match within the dataset consists of information such as:\n",
    "- Moves made\n",
    "- Date and time played\n",
    "- Player Elo\n",
    "- Match result\n",
    "- Game variant\n",
    "- Time control\n",
    "\n",
    "There are a number of features that we will need to construct from the database such as: \n",
    "- Game specific features\n",
    "- Player specific features\n",
    "- Recent form features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "\n",
    "\n",
    "In this project we aim to evaluate the effectiveness of three different machine learning implementations at classifying the outcomes of FIDE titled chess games from unlabeled match data. Each model (Logisitc Regression, Random Forests, and the Deep NN) will be trained on a curated sample database consisting of several derived features representing characteristics of the games pertinent to the games’ outcomes. For this we will need to use a variety of tools for accessing and manipulating the data to generate these special features. Pandas, and numpy will be instrumental in this preprocessing stage. Further imports will be required for sklearn and matplotlib for training/validation and analysis respectivel. Additionally, a library called pychess will be necessary for generating chess engine ratings and to help format move data for preprocessing. We will be using built in methods for training and validating data provided to us by sklearn. To measure the effectiveness of our model we will take Sayon Bhattacharjee’s LSTM solution published in the Towards Data Science article found here.\n",
    "\n",
    "- Logistic Regression\n",
    "    - Some possible features that can be used include the Elo rating of each player, the number of games they have played, the number of wins/losses/draws they have achieved, their age, and the length of the game. You would also need to engineer some features that capture the dynamics of the game, such as the number of pieces on the board, the pawn structure, and the control of the center.\n",
    "    - Simple implementation of a Logistic Classifier derived from the scikit-learn library which benefits from a less computationally intensive training and optimization phase in practice.\n",
    "    \n",
    "- Random Forest\n",
    "    - For a Random Forest classifier, you would use the same data as for a logistic regression classifier, i.e., historical data on FIDE-rated chess matches. The difference would be in how the data is represented and processed.\n",
    "    - Need to represent the data as a tree structure in a series of trees, with each node representing a feature and each branch representing a decision based on that feature.\n",
    "    - The features that you might consider using for a single decision tree would be similar to those for a logistic regression classifier, such as player rating, player age, player nationality, time control, and opening moves. However, the decision tree algorithm can handle non-linear relationships between features, so you might consider using features that are not suitable for a linear model, such as interactions between features or higher-order polynomials.\n",
    "    - More computationally intensive optimization phase than that of Logistic Regression due to recursive splitting and large amount of hyperparameters in trial\n",
    "\n",
    "- Neural Network\n",
    "    - For a deep neural network, you would typically use a similar set of features to those used in other machine learning models, such as player ratings, tournament results, and game characteristics. However, deep neural networks have the advantage of being able to learn more complex features and relationships than other models, so you could potentially include additional information such as time of day, location of the game, or other factors that may impact the outcome.\n",
    "    - Computationally intense model relative to other solutions proposed, but most rigorous model once optimized correctly and adjusted to correct feature representation of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "In the evaluation of binary chess outcome classification, simply implementing a confusion matrix of our algorithm’s results is most appropriate for visualizing the performance. In this situation, there is equal cost associated with both false positive rates and false negative rates, and there is equal cost associated with true positives and true negative rates. Consequently, we care about both the recall and precision of our models equally. This suggests that an f1-score is one primary metric we should use, since it is equally sensitive to both recall and precision. For example, predicting that Player 1 wins when they actually win is equally as important as being ‘accurate’ when predicting that Player 1 will win; the cost of a false positive is no different than the cost of a false negative. We may also explore some other classification error metrics such as likelihood ratios.\n",
    "\n",
    "$$ F_{1}=\\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of data privacy, we see no major concerns with our data as it is publicly available FIDE match information that is made public anytime a chess player agrees to a FIDE match. The biggest ethical concern that we could potentially see with the production of any well-functioning model for predicting FIDE titled chess matches would be the use of the model for gambling purposes. Although we don't foresee the prediction accuracy of our models being able to give a definitive answer to who will win a match, a good model could lead to an increase in chess match gambling which comes with its own host of harmful consequences.\n",
    "\n",
    "Additionally, we can highlight the concern that a prediction model could affect the way that players go about their matches if they know the predicted outcome of a game given specific features. This could be seen as an unfair advantage. The model, if then re-trained with new data, could also perform much more poorly as outcomes would now be affected by prior knowledge of the potential outcome of a game which would complicate further predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Schedule consistent meetings and keep in reliable communication regarding deadlines so nobody falls behind\n",
    "* Let the team know if any unexpected circumstances come up that would affect deadline completion for assigned work\n",
    "* Don’t be afraid to be stuck and ask for help. This will help us all better understand the problem and perhaps lead us toward a better solution.\n",
    "* Don’t be afraid to share any and all ideas that you think might be useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/20  |  2 PM |  Brainstorm topics/questions (all)  | Discuss and decide on final project topic; Discuss hypothesis; Do background research on topic; Discuss ideal dataset(s) and ethics; Draft project proposal | \n",
    "| 2/26 | 2 PM  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part| Identify best model approaches |\n",
    "| 2/29  | 2 PM  | Import & Wrangle Data; Do some EDA | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 3/3  | 12 PM  | Finalize wrangling/EDA; Begin programming for project | Discuss/edit project code |\n",
    "| 3/10  | 12 PM  | Complete project; Draft results/conclusion/discussion | Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"maharajnote\"></a>1.[^](#maharaj): Shiva Maharaj and Nick Polson and Alex Turk. (2021) Chess AI: Competing Paradigms for Machine Intelligence. https://doi.org/10.48550/arXiv.2109.11602<br> \n",
    "<a name=\"donote\"></a>2.[^](#do): Tiffany D. Do and Seong Ioi Wang and Dylan S. Yu and Matthew G. McMillian and Ryan P. McMahan. (2021) Using Machine Learning to Predict Game Outcomes Based on Player-Champion Experience in League of Legends. \n",
    "https://doi.org/10.48550/arXiv.2108.02799<br>\n",
    "<a name=\"articlenote\"></a>3.[^](#article): The Evolution of Chess AI (2022) Fluency. https://fluency.mcsaatchi.com/2022/09/01/the-evolution-of-chess-ai/#:~:text=Artificial%20intelligence%20has%20completely%20changed,20%20moves%20of%20their%20openings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
